{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb45ed1",
   "metadata": {},
   "source": [
    "## 1. Clean & Load the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97680a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines of corpus: 100000\n"
     ]
    }
   ],
   "source": [
    "with open(\"sampled_english_corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_lines = [line.strip() for line in f if line.strip()]  # remove empty lines\n",
    "\n",
    "# Optional: lowercase, remove punctuation, etc.\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "cleaned_lines = [clean_text(line) for line in raw_lines[:100]]\n",
    "print(f\"Number of lines of corpus: {len(cleaned_lines)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa947b",
   "metadata": {},
   "source": [
    "## 2. Tokenize the Corpus (word-level for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb6c33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokenized_lines = [line.split() for line in cleaned_lines]\n",
    "all_tokens = [token for line in tokenized_lines for token in line]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4a1a4",
   "metadata": {},
   "source": [
    "## 3. Build Vocabulary (filter rare words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9e221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30000\n",
    "token_freq = Counter(all_tokens)\n",
    "most_common = token_freq.most_common(vocab_size - 2)  # reserve 2 for <PAD> and <UNK>\n",
    "\n",
    "word2idx = {word: idx + 2 for idx, (word, _) in enumerate(most_common)}\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "word2idx[\"<UNK>\"] = 1\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2b304",
   "metadata": {},
   "source": [
    "## 4. Convert to Token IDs and Replace Rare Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c84d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_line(tokens):\n",
    "    return [word2idx.get(word, word2idx[\"<UNK>\"]) for word in tokens]\n",
    "\n",
    "encoded_lines = [encode_line(line) for line in tokenized_lines]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a084739",
   "metadata": {},
   "source": [
    "## 5. Prepare Training Sequences (Input â†’ Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99803784",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "inputs, targets = [], []\n",
    "\n",
    "for line in encoded_lines:\n",
    "    for i in range(len(line) - sequence_length):\n",
    "        seq_in = line[i : i + sequence_length]\n",
    "        seq_out = line[i + sequence_length]\n",
    "        inputs.append(seq_in)\n",
    "        targets.append(seq_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96dbc8",
   "metadata": {},
   "source": [
    "## 6. Build Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc75cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.inputs[idx]), torch.tensor(self.targets[idx])\n",
    "\n",
    "dataset = TextDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3141390",
   "metadata": {},
   "source": [
    "## 7. Define LSTM Model with Adaptive Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ba15543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=256, hidden_size=512):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.adaptive_softmax = nn.AdaptiveLogSoftmaxWithLoss(\n",
    "            in_features=hidden_size,\n",
    "            n_classes=vocab_size,\n",
    "            cutoffs=[2000, 10000, 20000],\n",
    "            div_value=4.0\n",
    "        )\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        emb = self.embedding(x)\n",
    "        out, _ = self.lstm(emb)\n",
    "        out = out[:, -1, :]  # take last hidden state\n",
    "        return self.adaptive_softmax(out, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d957e",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9796709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 7.2820\n",
      "Epoch 2: Loss = 6.0761\n",
      "Epoch 3: Loss = 4.7159\n",
      "Epoch 4: Loss = 3.1382\n",
      "Epoch 5: Loss = 1.6455\n",
      "Epoch 6: Loss = 0.6685\n",
      "Epoch 7: Loss = 0.2432\n",
      "Epoch 8: Loss = 0.1129\n",
      "Epoch 9: Loss = 0.0721\n",
      "Epoch 10: Loss = 0.0534\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMLanguageModel(vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x, batch_y)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b55c8",
   "metadata": {},
   "source": [
    "## 9. Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dfe8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path=\"model.pt\"):\n",
    "    torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_next_word(model=model, sentence=\"\", word2idx=word2idx, idx2word=idx2word, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = [word2idx.get(w, word2idx[\"<UNK>\"]) for w in sentence.strip().split()]\n",
    "        input_tensor = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        # Simulate prediction via LSTM (actually not used)\n",
    "        logits = model(input_tensor)\n",
    "        next_token_logits = logits[:, -1, :]  # [B, V]\n",
    "        predicted_idx = next_token_logits.argmax(dim=-1).item()\n",
    "\n",
    "        return idx2word.get(predicted_idx, \"<UNK>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55b253e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love you so much']\n"
     ]
    }
   ],
   "source": [
    "print(suggest_next_words(\"i love you so\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
